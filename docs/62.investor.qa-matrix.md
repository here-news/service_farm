# 62 — Investor Q&A Matrix

> Mapping tough investor questions to our answers via the Alignment Triangle

---

## The Alignment Framework

Every answer should trace back to the Alignment Triangle:

```
              EPISTEMIC VALUE (truth emerges)
                        △
                       /|\
                      / | \
                     /  |  \
    PSYCHOLOGICAL ←──┼──→ FINANCIAL
    (resolution)     |    (rewards)
```

**Core insight**: These three values reinforce, not compete.

---

## Category 1: Product-Market Fit

### Q1: "Why would anyone pay for news when information is free?"

**❌ Wrong framing**: We're not selling news.
**✅ Right framing**: We're selling **resolution**.

| Evidence | Source |
|----------|--------|
| People pay $15/mo for streaming to remove "what should I watch?" friction | Market data |
| People tip musicians who turn chaos into beauty | Human behavior |
| The relief when uncertainty collapses into clarity is physiological | Doc 68 §1 |

**One-liner**: "People don't pay for information. They pay for the feeling of 'now I know.'"

**Alignment**: Psychological → Financial (resolution converts to willingness-to-pay)

**Status**: ✅ Well addressed in docs 68 §4, 01 abstract

---

### Q2: "How is this different from existing fact-checkers?"

**The Gap**: Fact-checkers declare verdicts. We show resolution paths.

| Legacy Fact-Check | HERE.news |
|-------------------|-----------|
| Binary: True/False | Gradient: 0-100% resolved |
| Post-hoc | Real-time as evidence arrives |
| Expert authority | Community + algorithm |
| Static verdict | Evolving belief state |

**One-liner**: "Fact-checkers tell you what to believe. We show you how beliefs converge."

**Alignment**: Epistemic (methodology) + Psychological (visible progress)

**Status**: ✅ Well addressed in docs 01 §2.1, 68 §2

---

### Q3: "What's your cold-start strategy? How do you bootstrap content?"

**Phase 1: Legibility Events** (doc 68 §8)
- Start with events where resolution is **objectively measurable**
- Disaster death tolls (numbers converge)
- Election results (official counts)
- Court verdicts (definitive outcomes)

These build trust: "HERE.news said X would resolve to Y, and it did."

**Phase 2: B2B Design Partners** (doc 20)
- 3-5 teams in one vertical (research desks, newsrooms)
- Ship weekly, measure time-to-understanding

**One-liner**: "We start with events where you can verify we're right, then tackle events where you need us."

**Status**: ✅ Addressed in docs 20, 68 §8

---

### Q4: "Is this too complex for regular users?"

**The Response**: "Users don't need to understand the engine to drive the car."

| Analogy | Complex Backend | Simple UX |
|---------|-----------------|-----------|
| Spotify | Audio compression, ML recommendations | "Songs you'll like" |
| Google Maps | Graph algorithms, traffic ML | "15 minutes to work" |
| Uber | Surge pricing economics | "$12 to airport" |
| **HERE.news** | Bayesian inference, Shapley values | "85% resolved, 2 open questions" |

**Progressive Disclosure**:
| User Level | What They See |
|------------|---------------|
| Casual | Headlines + resolution % |
| Engaged | Contradictions + sources |
| Power user | Full metrics + claim graphs |

**One-liner**: "Big events are important. Red means debate. Green means settled. Your contribution made it better."

**Status**: ✅ Well addressed in doc 68 §7

---

## Category 2: Business Model

### Q5: "What's your revenue model?"

**Two-sided economy**:

| Segment | Model | Role |
|---------|-------|------|
| **B2B** (research desks) | SaaS subscription + usage | Profitable core |
| **B2C** (individuals) | Credits for contributions + crowdfunding | Volume engine |

**B2B Revenue Streams**:
- Seat-based dashboards ($X/user/mo)
- Usage metering (ingestion, LLM actions, alerts)
- Premium features (event chat, API access)

**Credits Economy**:
- Contributors earn for resolving disputes
- Users spend to crowdfund events they care about
- Mechanism aligns incentives with truth

**Status**: ✅ Addressed in docs 20, 23

---

### Q6: "What are your unit economics?"

| Metric | Low | High |
|--------|-----|------|
| Cost per page | $0.08 | $0.18 |
| Cost per event (~3 pages) | $0.29 | $0.63 |
| LLM cost per page | $0.04 | $0.07 |
| Infrastructure (amortized @10K pages) | $0.04 | $0.11 |

**Scaling Projections**:
| Tier | Pages/Mo | Total Monthly Cost |
|------|----------|-------------------|
| Demo | 1,000 | $450 |
| Pilot | 10,000 | $1,100 |
| Growth | 50,000 | $4,000 |
| Scale | 200,000 | $14,000 |

**Optimization Levers**: Model tiering (45% savings), caching (20% savings), local models

**Status**: ✅ Well addressed in doc 23

---

### Q7: "How do you make the credits economy work without becoming a Ponzi scheme?"

**Key design principles**:

1. **Credits are not equity** — They're utility tokens for platform actions
2. **Real value backing** — Credits fund actual compute/storage costs
3. **Contribution = Marginal Value** — Shapley values measure actual information gain
4. **Anti-speculation** — Credits optimize for use, not hoarding

**The Funding Ladder** (doc 68 §4):
| User State | Action | Motivation |
|------------|--------|------------|
| Curious | Browse free | "What's happening?" |
| Invested | Fund $0.50 | "Keep this event alive" |
| Engaged | Contribute source | "I can help clarify" |
| Committed | Stake in dispute | "I'll back my belief" |

**Status**: ⚠️ Partially addressed — Need more detail on anti-gaming mechanisms

---

## Category 3: Competition & Moat

### Q8: "What stops Google/OpenAI from doing this?"

**Structural conflicts**:

| Incumbent | Business Model | Why They Can't |
|-----------|---------------|----------------|
| Google | Ad revenue = engagement | Resolution reduces engagement |
| Meta | Social sharing = virality | Contradictions go viral, truth doesn't |
| OpenAI | API tokens | No incentive structure for community truth |
| News orgs | Authority = brand | Can't admit uncertainty |

**Our advantage**: We're built from scratch to align epistemic, psychological, and financial value. Incumbents would have to cannibalize their core business.

**One-liner**: "They optimize for engagement. We optimize for resolution. These are structurally opposed."

**Status**: ✅ Addressed in docs 68 §3, 24

---

### Q9: "What's your moat?"

**Three compounding loops**:

1. **Data flywheel**: More events → more claims → better clustering → better events
2. **Community flywheel**: More contributors → more resolution → more trust → more contributors
3. **Reputation flywheel**: Contributor track records → weighted contributions → higher quality → reputation value

**Network effects**:
- Each resolved event makes the next faster (entity reuse, claim patterns)
- Each trusted contributor reduces noise for everyone
- Each B2B customer adds training data for classification

**Status**: ✅ Addressed in docs 21, 24

---

### Q10: "How do you compete with prediction markets like Polymarket?"

| Polymarket | HERE.news |
|------------|-----------|
| Narrow: Binary yes/no questions | Broad: Any factual claim |
| Speculative: Bet on outcomes | Epistemic: Track evidence |
| Cold: Financial transactions | Warm: Resolution feeling |
| Zero-sum: Winners/losers | Positive-sum: Everyone gains clarity |

**Our angle**: Prediction markets ask "Will X happen?" We track "What do we know about X?"

**Alignment**: Polymarket is Financial-only. We're Financial + Psychological + Epistemic.

**Status**: ✅ Addressed in doc 68 §3

---

## Category 4: Technical Differentiation

### Q11: "What's technically novel about this?"

**EVENT Protocol innovations**:

1. **Three-state resolution (φ states)**:
   - φ⁰: Fully resolved (evidence converged)
   - φ±: Partially resolved (multiple viable interpretations)
   - φΩ: Irreducible plurality (value judgments)

2. **Fractal event structure**: Events nest/branch naturally (L1→L2→L3)

3. **Canonical name + Byline model**: Stable identifiers vs. volatile metrics

4. **Epistemic metabolism**: System knows what it doesn't know

**One-liner**: "We're the first system that admits uncertainty as a feature, not a bug."

**Status**: ✅ Well addressed in docs 01 §3, 13, 14

---

### Q12: "How do you handle AI-generated misinformation?"

**Defense layers**:

1. **Source provenance**: Every claim traced to origin
2. **Multi-source requirement**: Single-source claims flagged
3. **Contradiction surfacing**: Synthetic content creates detectable anomalies
4. **Community verification**: Economic incentives to flag fakes
5. **Temporal patterns**: AI-generated content has unnatural timing signatures

**Status**: ⚠️ Partially addressed — Need more detail in security model (doc 52)

---

### Q13: "How do you prevent gaming/manipulation?"

**Three-layer defense system**:

#### Layer 1: Credit Gas Fee (Economic Barrier)

Every influence action costs credits (denominated in cents):

| Action | Credit Cost | Why |
|--------|-------------|-----|
| Submit source | 1-5¢ | Prevents spam flooding |
| Vote on claim | 0.5-2¢ | Makes bot armies expensive |
| Stake in dispute | 10-50¢ | Significant cost for manipulation |
| Report content | 1¢ | Prevents frivolous reports |

**Like blockchain gas**: You must pay to use the network. Manipulation requires **sustained spending**.

#### Layer 2: EMA Decay (Self-Stabilizing System)

**Exponential Moving Average (EMA)** decays vote influence over time:

```
Influence(t) = α × Current + (1-α) × Influence(t-1)

Where α = smoothing factor (e.g., 0.1-0.3)
Older votes exponentially lose force
```

| Pattern | System Response |
|---------|-----------------|
| Burst of coordinated votes | Influence decays exponentially |
| Financial manipulation attempt | Must continuously re-spend to maintain effect |
| Old manipulation | Loses force naturally over time |

**Key insight**: Even with unlimited budget, influence **decays exponentially**. You can't "buy and hold" narrative control — you must **continuously pay** to maintain manipulation, while organic consensus persists naturally.

#### Layer 3: Event Qualia (Epistemic Immunity)

The event's own "qualia" — its internal epistemic structure — resists irrational narratives:

| Defense | Mechanism |
|---------|-----------|
| **φ-state anchoring** | Events converge to evidence, not popularity |
| **Contradiction surfacing** | Manipulation creates detectable anomalies |
| **Source independence** | Single-source campaigns get downweighted |
| **Temporal coherence** | Unnatural timing patterns flagged |

**Encoded in theory**: The event's belief state is updated by **evidence**, not by vote count. A thousand coordinated votes don't move a φ-state if they don't bring new evidence.

#### Economic Alignment Summary

| Gaming Attempt | Why It Fails |
|----------------|--------------|
| Flood with noise | Credits drain fast, no ROI |
| Sybil army | Each account needs credits; EMA decays influence |
| Narrative hijack | φ-states anchor to evidence, not volume |
| Long-term manipulation | Cost accumulates, influence decays |

**One-liner**: "Manipulation requires sustained cost. Truth has momentum."

**Status**: ✅ Well addressed

---

## Category 5: Market & Timing

### Q14: "Why now?"

**Three converging shifts** (doc 01 §1.2):

1. **Information chaos**: Billions of daily posts overwhelm fact-checking
2. **AI misinformation maturity**: Synthetic media makes contradiction inevitable
3. **AI tooling maturity**: Probabilistic AI + graph reasoning now feasible at scale

**The window**: First mover in "epistemic infrastructure" category.

**Status**: ✅ Well addressed in doc 01 §1.2

---

### Q15: "What's your TAM/SAM/SOM?"

**Market framing**: We're not competing in "news" — we're building **epistemic infrastructure** for the information age.

**TAM: Global Knowledge Economy**

| Segment | Size | Our Angle |
|---------|------|-----------|
| Digital media & news | $600B+ | Replace engagement with resolution |
| Social media (user attention) | $250B+ | Where misinformation spreads |
| Reference/encyclopedic (Wikipedia model) | Priceless public good | Add real-time, evolving knowledge |
| AI knowledge (Grokipedia, Perplexity) | Emerging | Provenance + community vs. AI hallucination |

**Competitive Positioning**:

| Platform | Model | Our Differentiation |
|----------|-------|---------------------|
| **Wikipedia** | Volunteer consensus, static articles | Real-time events, economic incentives, visible uncertainty |
| **Grokipedia/AI Knowledge** | AI writes "truth" | Human-in-loop, provenance chain, admits what it doesn't know |
| **Social Media** | Engagement = revenue | Resolution = revenue (aligned incentives) |
| **Legacy News** | Authority-based trust | Evidence-based trust with visible methodology |

**SAM: Information-Critical Segments**
- Research desks, newsrooms, risk/compliance: $5-10B
- OSINT, intelligence community: $2-5B
- Individual resolution-seekers (premium): $1-3B

**SOM: Initial Wedge**
- B2B design partners (Year 1): $500K-2M ARR
- Credit-funded events (Year 2): $1-5M

**The Wikipedia comparison is key**: Wikipedia proved crowdsourced knowledge works. We add:
1. **Real-time** (events as they happen, not after)
2. **Uncertainty-aware** (φ states, not false consensus)
3. **Economically incentivized** (credits, not just altruism)
4. **AI-resistant** (provenance vs. hallucination)

**Status**: ✅ Now addressed

---

## Category 6: Team & Execution

### Q16: "Why are you the right team to build this?"

**Core Team**:

| Role | Person | Background |
|------|--------|------------|
| **Co-founder, Vision** | Isaac Mao | [Pioneer in social software, open source, and cognitive science. Early Chinese blogger/technologist. Founded Sharism Lab.] |
| **Co-founder, Protocol** | Andrés Salgado | [Epistemology + formal methods. Designed EVENT protocol grounded in Jaynes probability theory.] |
| **[CTO Placeholder]** | TBD | [Distributed systems, ML infrastructure] |
| **[Head of Product Placeholder]** | TBD | [Consumer/prosumer products, community building] |

**Why this team**:
1. **Theoretical depth**: Jaynes-grounded epistemology isn't bolted on — it's the foundation
2. **Technical capability**: Working demo with fractal events, real-time updates, LLM pipeline
3. **Network**: [Connections to research community, early adopters, potential partners]

**Key hires needed**:
- ML/AI lead (claim extraction, entity resolution at scale)
- Community lead (contributor acquisition, trust & safety)
- Enterprise sales (B2B design partners)

**Status**: ✅ Addressed with placeholders for expansion

---

### Q17: "What's your 18-month roadmap?"

**Phases** (doc 21):
- Phase 1: Design partners, core pipeline
- Phase 2: Community features, credits
- Phase 3: Scale, premium features

**Status**: ✅ Addressed in doc 21

---

## Summary: Readiness Matrix

| Category | Questions | Well Addressed | Partial | Gap |
|----------|-----------|----------------|---------|-----|
| Product-Market Fit | 4 | 4 | 0 | 0 |
| Business Model | 3 | 2 | 1 | 0 |
| Competition/Moat | 3 | 3 | 0 | 0 |
| Technical | 3 | 2 | 1 | 0 |
| Market/Timing | 2 | 2 | 0 | 0 |
| Team/Execution | 2 | 2 | 0 | 0 |
| **Total** | **17** | **15 (88%)** | **2 (12%)** | **0 (0%)** |

**Improvement**: From 71% → 88% well addressed after adding:
- TAM/SAM/SOM with Wikipedia/Grokipedia comparison
- Three-layer gaming defense (Credits + EMA + Qualia)
- Team structure with placeholders

---

## Recommended Actions

### Completed
1. ✅ Alignment narrative doc (68) — DONE
2. ✅ TAM/SAM/SOM with Wikipedia/Grokipedia comparison — DONE (in doc 69)
3. ✅ Three-layer gaming defense (Credits + EMA + Qualia) — DONE (in doc 69)
4. ✅ Team structure with placeholders — DONE (in doc 69)

### Short-term (pitch deck prep)
5. Create 10-slide pitch deck per doc 68 §10
6. Fill in team placeholders with actual bios/connections
7. Develop 2-3 "legibility event" case studies from demo

### Medium-term (due diligence readiness)
8. Formalize EMA decay algorithm in security model (doc 52)
9. Customer validation data (design partner feedback)
10. Competitive landscape matrix with feature comparison (expand doc 24)

---

## Key One-Liners for Investor Conversations

| Question | One-Liner |
|----------|-----------|
| Why pay? | "People don't pay for information. They pay for the feeling of 'now I know.'" |
| vs Google? | "They optimize engagement. We optimize resolution. Structurally opposed." |
| Too complex? | "Users don't need to understand the engine to drive the car." |
| Manipulation? | "Manipulation requires sustained cost. Truth has momentum." |
| vs Wikipedia? | "Real-time + uncertainty-aware + economically incentivized + AI-resistant" |
| vs AI knowledge? | "Provenance chain vs. hallucination. We admit what we don't know." |
| Business model? | "We're building epistemic infrastructure — where truth has a business model." |

---

*The alignment narrative transforms complex answers into simple truths: We make resolution possible, and resolution is valuable.*
