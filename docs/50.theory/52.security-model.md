# 52 — Security Model: Attack Resistance and Governance

This document details the security mechanisms that protect EVENT from manipulation.

Related:
- `docs/01.whitepaper.md`
- `docs/20.business.plan.md` (Why Credits section)
- `docs/50.theory/51.ontology-mapping.md`

## Threat Model

### Attacker Goals

1. **False convergence**: Force the system to settle on a false claim
2. **Suppression**: Prevent true claims from gaining visibility
3. **Disruption**: Prevent any convergence (permanent chaos)
4. **Gaming**: Extract rewards without genuine epistemic contribution

### Attack Vectors

| Attack | Description | Traditional Platform Vulnerability |
|--------|-------------|-----------------------------------|
| **Sybil** | Create many fake accounts to amplify false claims | Votes count equally |
| **Coherence Bomb** | Coordinate false evidence to force quick convergence | No structural similarity detection |
| **Oracle Capture** | Control the priors/weights to bias all inference | Centralized editorial control |
| **Grief Staking** | Stake against obvious truths to extract rewards | No penalty for bad-faith disputes |
| **Source Laundering** | Create fake "independent" sources | No provenance verification |

## Defense Mechanisms

### 1. Structural Similarity Penalty (SSP)

**Problem**: Coordinated propaganda networks create many "sources" that are actually copies or minor variations of each other.

**Solution**: Discount corroboration from sources with high structural similarity.

```
Reward(c) ∝ Δh(c) × (1 - SSP(c))
```

Where SSP(c) measures:
- **Metadata similarity**: Same publication time, same IP ranges, same hosting
- **Embedding similarity**: Semantic vectors too close (near-duplicate text)
- **Citation network**: Sources that only cite each other
- **Temporal correlation**: Claims that appear in lockstep

**Effect**: To fake corroboration, an attacker must create genuinely diverse sources—exponentially more expensive than copy-pasting.

### 2. Entropy-Increasing Reward (EIR)

**Problem**: Pure coherence-seeking creates epistemic monoculture. Dissent is suppressed even when it's correct.

**Solution**: Reward productive contradiction that ultimately improves coherence.

A contribution that *increases* entropy in the short term can receive rewards if:
- It introduces a genuinely new hypothesis
- That hypothesis later gains corroboration
- Or it clarifies the scope of existing claims (disambiguation)

**Formula**:
```
EIR(c) = α × Δh_long(c) if Δh_short(c) < 0
```

Where:
- Δh_short = immediate entropy change (negative = increased uncertainty)
- Δh_long = entropy change after N subsequent updates

**Effect**: Whistleblowers and contrarians are protected. The system doesn't crush minority views that turn out to be correct.

### 3. Decentralized Priors Governance Layer (DPGL)

**Problem**: Priors P(H) determine initial beliefs. Whoever controls priors controls inference.

**Solution**: Decentralize and make priors transparent/contestable.

**Mechanisms**:

1. **Dynamic priors**: Priors evolve based on real historical performance, not fixed assumptions
   - Source priors update based on track record (claims corroborated vs contradicted)
   - Domain priors learned from resolution outcomes

2. **Transparent governance**:
   - Prior update logs are public
   - A/B testing of weighting schemes with published results
   - Community can challenge prior assumptions

3. **Forkability**: If governance becomes captured or biased, the protocol is forkable
   - Core EVENT logic is open
   - Communities can establish alternative prior structures
   - Data portability ensures no lock-in

**Effect**: No single entity can permanently bias the system. Capture is detectable and correctable.

### 4. Credit-Based Rate Limiting

**Problem**: Spam attacks, grief staking, rapid-fire manipulation.

**Solution**: All consequential actions cost credits.

| Action | Credit Cost | Rationale |
|--------|-------------|-----------|
| URL submission | 10 | Prevents spam ingestion |
| Dispute filing | 100+ | Prevents frivolous disputes |
| Evidence submission | 10-50 | Skin in the game |
| Vote/stake | Variable | Proportional to influence |

**Additional constraints**:
- Minimum account age (7 days) for high-impact actions
- Cooldown between stakes (1 hour)
- Maximum stake per dispute
- Progressive requirements as influence grows

**Effect**: Attacks have real costs. An attacker must spend significant resources, making large-scale manipulation economically infeasible.

### 5. Source Diversity Requirements

**Problem**: Single source dominance can skew event understanding.

**Solution**: Require minimum source diversity for high-confidence claims.

For a claim to reach confidence > 0.8:
- Minimum 3 independent sources
- No single source > 40% of evidence weight
- Sources must span at least 2 domain categories (e.g., wire + local news)

**Effect**: "Trust me" doesn't work. Extraordinary claims require extraordinary (and diverse) evidence.

## Coherence Bomb: Detailed Analysis

### The Attack

1. Attacker creates N "independent" sources (websites, social accounts)
2. Sources simultaneously publish coordinated false claims
3. System sees apparent multi-source corroboration
4. Entropy drops rapidly → false convergence to φ⁰

### Why It's Hard with EVENT

**SSP detection**:
- Sources created around same time → flagged
- Similar writing patterns → embedding similarity detected
- Coordinated publication → temporal correlation flagged

**Diversity requirements**:
- All sources are same "type" (unknown/new) → low initial prior
- No established reputation → limited influence
- Missing cross-domain corroboration → can't reach high confidence

**Economic cost**:
- Each source needs credits to submit
- Each claim needs stakes to influence resolution
- Total cost scales with attack size

**Time defense**:
- Rapid convergence triggers review
- High temperature events get more scrutiny
- φ⁰ requires sustained low entropy, not a spike

### Residual Risk

Sophisticated state actors with:
- Long-term planted sources (years of reputation building)
- Genuine-seeming diversity (different languages, regions, outlets)
- Patience (slow, steady influence rather than spike)

**Mitigation**: This is the hardest attack. Defense relies on:
- Community vigilance (humans in the loop for high-stakes events)
- Long-term reputation tracking (eventual detection)
- Forkability (communities can reject captured priors)

## Oracle Problem

### The Risk

If priors become "ground truth," whoever sets priors controls inference:
- A captured DPGL could systematically bias toward certain narratives
- "Neutral" priors are themselves a political choice
- Expert panels can be wrong or biased

### DPGL Mitigations

1. **No permanent priors**: All priors update based on outcomes
2. **Multiple prior sets**: Different communities can run different priors
3. **Transparency**: Prior derivation is public and auditable
4. **Competition**: Better priors attract users; market pressure for accuracy

### Philosophical Acceptance

Some prior-setting is unavoidable. EVENT makes it:
- Explicit (not hidden)
- Auditable (you can see what priors were used)
- Correctable (priors update with evidence)
- Forkable (you can reject priors you disagree with)

This is better than hidden editorial bias, even if imperfect.

## Known Limitations

1. **Garbage in, garbage out**: EVENT can't verify claims that have no corroboration pathway
2. **Speed vs accuracy tradeoff**: Fast-moving events have high uncertainty by design
3. **Human attention still scarce**: Curators are needed for edge cases
4. **Adversarial ML**: Sophisticated attackers will evolve; defenses must evolve too

## Security Principles

1. **Defense in depth**: Multiple overlapping mechanisms
2. **Economic alignment**: Attacks must be expensive
3. **Transparency over secrecy**: Open mechanisms, auditable decisions
4. **Graceful degradation**: Even compromised states are detectable and recoverable
5. **Human oversight**: Automation augments, doesn't replace, human judgment

Prev: `docs/50.theory/51.ontology-mapping.md`
Next: `docs/60.workers.semantic-design.md`
