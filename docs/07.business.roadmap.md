# 07 — Roadmap

**Product**: HERE.news Breathing Knowledge System (resource-first, evidence-driven knowledge graph)
**Horizon**: 12–18 months
**Owner**: (fill)
**Last updated**: 2025-12-13

Related: `docs/01.vision.md`

## Vision (From Recent GH Issues)

We are building a **LiveWorld**: a living container for evolving knowledge structures, where automated extraction is complemented by **community signals** that act as Bayesian priors.

- **LiveEvent**: active metabolism (existing)
- **LiveEntity**: passive/lazy organism, “awakens” on triggers (event mentions, community reports, evidence submissions)
- **LiveRelationship**: evolving connections with uncertainty
- **CommunitySignalProcessor**: credit-weighted signals (votes, disputes, evidence, reports) that update priors with an audit trail

Community interaction is not “comments”; it is a structured resolution pipeline:
- Contradictions surfaced automatically
- Debates with stake-weighted participation
- Evidence submissions and curator review thresholds (e.g., 1k/10k/50k credits)

Sources: GH issues #13 (LiveWorld), #12 (Credits), #9 (Reliability/Epistemics/Observability).
Additional roadmap drivers: #15 (event hierarchy), #3 (multi-signal formation), #17 (reputation), #16 (event chat), #14 (archive), #4 (timezone), #2 (cross-lingual entity resolution).

## Goals

1. Ship a usable MVP that turns artifacts (web, files, media, data) into trustworthy, queryable events.
2. Prove retention via recurring value (alerts, dashboards, timelines) for a defined ICP.
3. Establish defensibility via (a) data flywheel (sources → claims → events → graph), and (b) community curation + incentives.
4. Reach a repeatable revenue motion (B2B first, optional B2C later).

## Target Customer (ICP)

**Primary (B2B)**:
- Newsrooms and research desks (fact-checking, investigations)
- Policy/think-tank analysts (issue monitoring, event timelines)
- Risk & compliance teams (entity/event monitoring, change detection)

**Secondary**:
- OSINT / intelligence contractors
- Market research and PR monitoring

## Value Proposition

- **Fast**: Instant “best shot” response, progressively enriched in background.
- **Trustworthy**: Every claim anchored to sources; confidence is explicit and evolving.
- **Queryable**: Events + entities form a navigable graph (timelines, clusters, contradictions).
- **Actionable**: Alerts, summaries, and structured exports for downstream workflows.

## Strategy (Phased)

### Phase 0 — Stabilize Demo → Product Baseline (Weeks 1–3)
**Outcome**: Reliable ingestion pipeline and a reproducible dev/prod path.

- Reliability hardening (from GH): transactional outbox for job emission, DLQ + replay tooling, idempotency keys
- Observability: traces across stages (API → workers → topology), core latency/error metrics
- Contract layer: versioned inter-worker schemas (Pydantic) for payload stability
- Data quality: dedupe, language detection, better extraction coverage
- UX baseline: a single “submit URL → see status → see event” flow
- Deliverable: “MVP readiness checklist” + baseline metrics dashboard

**Exit criteria**
- P95 submit latency < 200ms (stub/best-shot)
- Background pipeline completes successfully for ≥80% of a defined URL corpus
- Clear, stable event schema + export (JSON)

### Phase 1 — MVP: URL → Claims → Events for One Vertical (Weeks 4–10)
**Outcome**: A narrow, lovable product for one ICP with repeatable workflows.

- Choose a vertical (e.g., public policy, finance, conflict, local government)
- Event formation: multi-signal relatedness, update-vs-merge detection, better clustering/merge (issues #3, #15)
- Entity resolution: cross-lingual matching and romanization variants (issue #2)
- Time handling: timezone persistence + ambiguity handling (issue #4)
- Epistemics: source diversity signals (domain entropy, near-duplicate detection) feeding confidence
- Workflows: saved queries, timelines, export, shareable links
- Trust features: per-claim citations, confidence display, “why this event?” explanation
- Deliverable: pilot-ready MVP for 3–5 design partners

**Exit criteria**
- Weekly active usage in pilot accounts (define target)
- ≥60% of “events” judged useful by pilot users (qualitative scoring rubric)

### Phase 2 — Retention: Monitoring + Alerts + Story Layers (Weeks 11–18)
**Outcome**: Users return because the system keeps them ahead of changes.

- Monitoring: watchlists (entities/topics), change detection, alert routing (email/webhook)
- Story layer: human-curated narratives that reference events/claims (separate from “facts”)
- Collaboration: annotations, issue flags, tasking and review states
- Deliverable: “Analyst workstation” experience (dashboards + alerts + narratives)

**Exit criteria**
- D30 retention target met for pilots (define)
- Alert relevance precision target met (define)

### Phase 3 — Community System: Credits → Signals → Debate (Months 4–9)
**Outcome**: A working trust loop where community actions produce measurable epistemic improvements.

- Credits foundation (from GH): credit ledger, profile UI, mock deposits/withdrawals → payments later
- Community signals: model + repository, credit-weighted prior calculation, threshold escalations, audit trail
- Debate experience: auto-surfaced contradictions, positions/stakes, evidence submissions, curator queue

**Exit criteria**
- At least one end-to-end loop: contradiction → debate → resolution → prior update → UI reflects change
- Abuse resistance baseline: rate limits + minimum requirements to stake (define)

### Phase 4 — Resolution Pipeline + Payouts (Months 6–12)
**Outcome**: Disputes resolve predictably; incentives align with verification.

- Resolution voting (stake-weighted), and automation from resolution → prior update
- Credit flows for resolution outcomes (distribution policy decided)
- Payments rollout: Stripe deposits, withdrawals with thresholds + (optional) KYC

**Exit criteria**
- Dispute resolution cycle time target met (define)
- Clear economic policy for stake outcomes (documented + enforced)

### Phase 5 — Premium Surfaces (Months 6–12)
**Outcome**: Monetizable user experiences that deepen engagement.

- Premium “chat with an event” (claim-grounded, contradiction-aware) with credit gating (issue #16)
- Reputation surfaces in UI (publishers/authors/users) to improve trust and triage (issue #17)

### Phase 6 — Persistence & Archive (Months 6–18)
**Outcome**: Durable evidence with transparent storage health and credit-backed funding.

- Archive page + content hashing + integrity verification (issue #14)
- Credit-backed tiers with decay/top-ups; health monitoring; alerts
- Optional foundation for provider incentives / decentralization

### Phase 7 — Go-to-Market Scale (Months 9–18)
**Outcome**: Repeatable acquisition + revenue.

- Packaging: seat-based + usage tiers; exports/API; enterprise controls
- Partnerships: data providers, newsroom tooling, OSINT platforms
- Compliance: audit logs, data retention, security posture
- Deliverable: v1 pricing + onboarding + sales collateral

## Milestones (Suggested)

1. **M0**: Define ICP + success rubric + pilot list (Week 1)
2. **M1**: Reliability baseline: outbox + DLQ + tracing (Week 3)
3. **M2**: MVP schema + provenance UI shipped (Week 6)
4. **M3**: First design partner live; weekly feedback loop (Week 8)
5. **M4**: Monitoring + alerts beta (Week 14)
6. **M5**: Narrative/story layer beta (Week 16)
7. **M6**: Credits ledger + profiles shipped (Month 4–6)
8. **M7**: Debate + resolution MVP shipped (Month 6–9)
9. **M8**: First paid pilot / LOI (Month 6–12)

## Metrics (North Star + Supporting)

**North Star (pick one)**
- “Verified events delivered per active account per week”
- “Time-to-understanding” for a monitored topic (user-reported + behavioral)

**Supporting**
- Ingestion success rate by source type
- Event merge precision/recall (human-evaluated sample)
- Citation coverage per claim/event
- Alert precision (relevance) and latency
- Weekly active users per account; D30 retention

## Risks & Mitigations

- **Extraction brittleness** → multiple extractors + fallbacks, corpus-based testing
- **Hallucinated claims** → strict citation requirements, conservative confidence defaults, refusal modes
- **Event clustering errors** → human-in-the-loop merge tools, explainability, reversible merges
- **Cost blowups** → caching, batching, model tiering, truncation policies
- **Trust and abuse** → audit trails, rate limits, reputation gating, moderation tools

## Decisions Needed (To Make This Real)

1. Pick the **first ICP** and vertical.
2. Define the **pilot success rubric** (what “useful event” means).
3. Confirm database stance: PostgreSQL-first; any graph indexing must remain rebuildable.
4. Decide the initial **monetization wedge** (API/export vs dashboards vs alerts).
5. Set credit policy: stake loss (burn vs redistribute), minimums, and curator selection.

Next: `docs/08.business.operations.md`
