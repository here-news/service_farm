# 26 — Experimental Calibration: Validating the Epistemic Engine

> Empirical evidence that the theory works

---

## Executive Summary

We validated the Universal Epistemic Engine through six experiments on real data (1,215 claims, 740 entities, 16 events). Key findings:

| Finding | Evidence | Impact |
|---------|----------|--------|
| **Independence is everything** | r = -1.000 | More independent sources = lower entropy, exactly as Jaynes predicted |
| **65% of sources are copies** | Embedding analysis | Naive corroboration counting overestimates certainty by ~3x |
| **Calibrated formula works** | MAE = 0.172 | 56% more accurate than naive entropy |
| **Levels emerge from structure** | 7-level chains found | Don't assign abstraction—compute it |
| **Entity routing is valid** | 27x speedup | Claims cluster around shared entities |

This is not theoretical. It's validated on real news data.

---

## The Calibrated Entropy Formula

The empirically optimized formula:

```python
def compute_entropy(n_corr, n_contra, independence_ratio=0.35):
    """
    Calibrated entropy formula.

    Validated against LLM assessments.
    MAE = 0.172, Correlation = 0.71
    """
    base = 1.0

    # Effective corroboration (discounted by independence)
    effective_corr = n_corr * independence_ratio

    # Calibrated weights from optimization
    corr_reduction = 0.49 * (effective_corr ** 0.30)
    contra_addition = 0.27 * (n_contra ** 0.31)

    entropy = base - corr_reduction + contra_addition
    return max(0.05, min(0.99, entropy))
```

### Key Parameters (Optimized)

| Parameter | Value | Meaning |
|-----------|-------|---------|
| `independence_ratio` | 0.35 | Only 35% of "corroborations" are truly independent |
| `corr_weight` | 0.49 | Corroboration reduces entropy |
| `corr_exponent` | 0.30 | Diminishing returns (log-like) |
| `contra_weight` | 0.27 | Contradiction increases entropy |
| `contra_exponent` | 0.31 | Similar diminishing returns |

### Why These Values?

The 0.30 exponent means:
- 1 corroboration → 0.49 reduction
- 4 corroborations → 0.75 reduction (not 4×)
- 16 corroborations → 0.98 reduction

This matches Bayesian intuition: the first corroboration is worth more than the 100th.

---

## Experiment 1: Universal Topology Validation

**Question**: Does the entropy formula correctly order claims by uncertainty?

**Method**: Compute entropy for claims with different support structures. Compare to expected ordering.

**Results**:

| Claim Type | Average Entropy | Expected |
|------------|-----------------|----------|
| Corroborated | 0.418 | Low ✓ |
| Contested | 0.792 | Medium ✓ |
| Isolated | 1.000 | High ✓ |

**Critical Finding**: Independence amplification correlation = **-1.000** (perfect).

This means: more independent sources = lower entropy, exactly as Jaynes predicted. The formula is correctly implementing maximum entropy inference.

---

## Experiment 2: The Copying Problem

**Question**: Are news sources independent or copying each other?

**Method**: Analyze semantic similarity between sources covering the same event.

**Results**:

| Metric | Value |
|--------|-------|
| Average independence ratio | 0.35 |
| Likely copies | **65%** |
| High dependency pairs | 12 of 20 |

**Critical Finding**: Most "corroborations" are copies.

```
100 outlets copying AP ≠ 100 independent sources
```

Naive counting overestimates certainty by ~3x. The calibrated formula discounts by `independence_ratio = 0.35`.

### Why This Matters

Traditional news aggregators count sources:
- "100 sources confirm this" → high confidence

Reality:
- 65 are copying the same wire service
- 35 are actually independent
- True confidence is much lower

Our system correctly discounts for copying.

---

## Experiment 3: LLM Relationship Validation

**Question**: Do automatically detected relationships match human judgment?

**Method**: Compare system-detected CORROBORATES/CONTRADICTS to GPT-4 classification.

**Results**:

| Metric | Value |
|--------|-------|
| Agreement rate | 65% |
| Common misclassification | CORROBORATES → UPDATES |

**Finding**: Many "corroborations" are actually updates (new details about same topic).

This suggests we need finer-grained relationship types:
- CORROBORATES (same claim, independent source)
- UPDATES (adds new information)
- REFINES (same claim, more precision)
- CONTRADICTS (conflicting claim)

---

## Experiment 4: Computational Scalability

**Question**: Can this scale to real workloads?

**Method**: Compare brute-force vs. optimized routing strategies.

**Results**:

| Strategy | Time (1,215 claims) | Projection (100k claims) |
|----------|---------------------|--------------------------|
| brute_force + full_recompute | 10.17s | 19 hours |
| entity_routing + lazy | **0.37s** | **37 seconds** |

**Finding**: Entity routing provides **27x speedup**.

Claims cluster around shared entities. Routing by entity is epistemically valid AND computationally efficient.

---

## Experiment 5: Formula Calibration

**Question**: Can we optimize the formula parameters?

**Method**: Use LLM assessments as ground truth. Optimize parameters to minimize error.

**Results**:

| Formula | Mean Absolute Error | Correlation |
|---------|---------------------|-------------|
| Original (v1) | 0.394 | 0.65 |
| Fixed (v2) | 0.352 | 0.66 |
| **Calibrated (v3)** | **0.172** | **0.71** |

**Finding**: Calibration reduces error by **56%**.

The optimized parameters (0.49, 0.30, 0.27, 0.31) are not arbitrary—they're derived from real data.

---

## Experiment 6: Emergent Abstraction Levels

**Question**: Do abstraction levels emerge from structure?

**Method**: Compute `level(claim) = max(level(supporters)) + 1` recursively from ground claims.

**Results**: Longest chain found (7 levels):

```
L0: "Jimmy Lai jailed for 1,800 days"
 └─L1: "Jimmy Lai jailed for 1,700 days"
    └─L2: "Held 1,800 days in solitary"
       └─L3: "Arbitrary detention almost five years"
          └─L4: "In prison more than five years"
             └─L5: "Held in detention five years"
                └─L6: "Already spent five years in jail"
```

**Finding**: Levels are computed from graph structure, not assigned.

A "frame" like "systemic safety failures" isn't assigned L3—it emerges at L3 because it's supported by L2 claims, which are supported by L1 claims, which are supported by L0 observations.

---

## What's Actually Contested

LLM analysis revealed three types of contestation:

| Type | Example | Resolution Path |
|------|---------|-----------------|
| **NUMBER** | Death toll: 36 vs 128 vs 156 vs 160 | Official source |
| **CAUSE** | "campus event" vs "campus debate" | Eyewitness accounts |
| **ATTRIBUTION** | Who said what, when | Direct quotes with timestamps |

**Insight**: Contradictions reveal exactly what is uncertain. These should be surfaced prominently.

---

## Entity Gravity

Claims cluster around shared entities:

| Entity | Claims | Coverage |
|--------|--------|----------|
| Jimmy Lai | 114 | detention, health, trial, fairness |
| Hong Kong | 105 | fire, politics, safety |
| Donald Trump | 84 | foreign policy, statements |

**Insight**: Entity routing is epistemically valid. Entity profiles emerge from aggregation.

---

## The Epistemic Engine Demo

A working engine that takes any user claim and:

1. **Decomposes** it into testable sub-claims
2. **Searches** the knowledge graph via entities
3. **Analyzes** evidence (support/contradiction)
4. **Computes** entropy using calibrated formula
5. **Suggests** what evidence would change coherence

### Example Output

**Query**: "The Hong Kong fire killed over 150 people"

```
Type: FACT
Coherence: 42%
Status: CONTESTED

Supporting:
- "death toll rose to 160"
- "death toll hits 128"

Contradicting:
- "at least 44 killed"
- "at least 36 killed"
- "at least 40 killed"

Contested aspect: THE EXACT NUMBER OF FATALITIES
Most important question: What is the confirmed death toll?
```

The system shows exactly WHY it's uncertain and WHAT would resolve it.

---

## Implications

### For the Product

1. **Coherence badges** on every claim
2. **Contradiction surfacing** for contested facts
3. **Entity pages** aggregating all claims about a person/org
4. **Source independence tracking**

### For the Theory

1. **Entropy is the universal index** — works at all scales
2. **Independence is the key variable** — copying breaks naive counting
3. **Levels emerge from structure** — don't assign, compute
4. **Same operation at every scale** — claims supporting claims

### For Positioning

This is not a news aggregator. It is **the scientific method as software**.

---

## References

- Jaynes, E.T. "Probability Theory: The Logic of Science" (2003)
- `backend/test_eu/EPISTEMIC_TOPOLOGY_REPORT.md` — Full experimental report
- `20.theory.entropy-reduction.md` — Core theoretical foundation
- `21.theory.universal-topology.md` — Claim topology structure
- `31.arch.uee.md` — Universal Epistemic Engine implementation

---

*The calibrated formula is not arbitrary. It's derived from real data, validated against LLM judgment, and grounded in Jaynes' probability theory.*
